{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9873477038425493,
  "eval_steps": 500,
  "global_step": 25500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011715089034676664,
      "grad_norm": 2.5415332317352295,
      "learning_rate": 0.0004980474851608872,
      "loss": 3.0772,
      "step": 100
    },
    {
      "epoch": 0.023430178069353328,
      "grad_norm": 2.224560499191284,
      "learning_rate": 0.0004960949703217745,
      "loss": 2.9641,
      "step": 200
    },
    {
      "epoch": 0.035145267104029994,
      "grad_norm": 2.1707069873809814,
      "learning_rate": 0.0004941424554826617,
      "loss": 2.9,
      "step": 300
    },
    {
      "epoch": 0.046860356138706656,
      "grad_norm": 2.2945117950439453,
      "learning_rate": 0.0004921899406435489,
      "loss": 2.7634,
      "step": 400
    },
    {
      "epoch": 0.05857544517338332,
      "grad_norm": 2.821709632873535,
      "learning_rate": 0.0004902374258044361,
      "loss": 2.7573,
      "step": 500
    },
    {
      "epoch": 0.07029053420805999,
      "grad_norm": 3.625251531600952,
      "learning_rate": 0.0004882849109653233,
      "loss": 2.7805,
      "step": 600
    },
    {
      "epoch": 0.08200562324273665,
      "grad_norm": 4.410861015319824,
      "learning_rate": 0.0004863519212746017,
      "loss": 2.7153,
      "step": 700
    },
    {
      "epoch": 0.09372071227741331,
      "grad_norm": 2.8487977981567383,
      "learning_rate": 0.0004843994064354889,
      "loss": 2.7473,
      "step": 800
    },
    {
      "epoch": 0.10543580131208997,
      "grad_norm": 3.247021436691284,
      "learning_rate": 0.0004824468915963762,
      "loss": 2.6552,
      "step": 900
    },
    {
      "epoch": 0.11715089034676664,
      "grad_norm": 3.4625401496887207,
      "learning_rate": 0.0004804943767572634,
      "loss": 2.6531,
      "step": 1000
    },
    {
      "epoch": 0.12886597938144329,
      "grad_norm": 3.354572057723999,
      "learning_rate": 0.0004785418619181506,
      "loss": 2.5728,
      "step": 1100
    },
    {
      "epoch": 0.14058106841611998,
      "grad_norm": 3.5039639472961426,
      "learning_rate": 0.00047660887222742896,
      "loss": 2.661,
      "step": 1200
    },
    {
      "epoch": 0.15229615745079664,
      "grad_norm": 3.787827730178833,
      "learning_rate": 0.00047465635738831616,
      "loss": 2.6015,
      "step": 1300
    },
    {
      "epoch": 0.1640112464854733,
      "grad_norm": 3.3805348873138428,
      "learning_rate": 0.0004727038425492034,
      "loss": 2.5387,
      "step": 1400
    },
    {
      "epoch": 0.17572633552014996,
      "grad_norm": 3.36317777633667,
      "learning_rate": 0.0004707513277100906,
      "loss": 2.5419,
      "step": 1500
    },
    {
      "epoch": 0.18744142455482662,
      "grad_norm": 4.258591651916504,
      "learning_rate": 0.0004687988128709778,
      "loss": 2.5522,
      "step": 1600
    },
    {
      "epoch": 0.1991565135895033,
      "grad_norm": 4.761959075927734,
      "learning_rate": 0.00046684629803186507,
      "loss": 2.51,
      "step": 1700
    },
    {
      "epoch": 0.21087160262417995,
      "grad_norm": 3.727017641067505,
      "learning_rate": 0.00046489378319275227,
      "loss": 2.5217,
      "step": 1800
    },
    {
      "epoch": 0.2225866916588566,
      "grad_norm": 3.381781578063965,
      "learning_rate": 0.00046294126835363947,
      "loss": 2.5623,
      "step": 1900
    },
    {
      "epoch": 0.23430178069353327,
      "grad_norm": 2.881222724914551,
      "learning_rate": 0.0004609887535145267,
      "loss": 2.489,
      "step": 2000
    },
    {
      "epoch": 0.24601686972820994,
      "grad_norm": 3.559231996536255,
      "learning_rate": 0.0004590362386754139,
      "loss": 2.4943,
      "step": 2100
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 3.603713035583496,
      "learning_rate": 0.0004570837238363011,
      "loss": 2.4951,
      "step": 2200
    },
    {
      "epoch": 0.2694470477975633,
      "grad_norm": 4.104010581970215,
      "learning_rate": 0.00045513120899718843,
      "loss": 2.4831,
      "step": 2300
    },
    {
      "epoch": 0.28116213683223995,
      "grad_norm": 3.673733949661255,
      "learning_rate": 0.00045317869415807563,
      "loss": 2.4613,
      "step": 2400
    },
    {
      "epoch": 0.2928772258669166,
      "grad_norm": 6.115017414093018,
      "learning_rate": 0.00045122617931896283,
      "loss": 2.4748,
      "step": 2500
    },
    {
      "epoch": 0.3045923149015933,
      "grad_norm": 4.156976222991943,
      "learning_rate": 0.0004492736644798501,
      "loss": 2.4418,
      "step": 2600
    },
    {
      "epoch": 0.31630740393626994,
      "grad_norm": 3.1394004821777344,
      "learning_rate": 0.0004473211496407373,
      "loss": 2.4796,
      "step": 2700
    },
    {
      "epoch": 0.3280224929709466,
      "grad_norm": 3.8007802963256836,
      "learning_rate": 0.0004453686348016245,
      "loss": 2.4996,
      "step": 2800
    },
    {
      "epoch": 0.33973758200562326,
      "grad_norm": 3.396369218826294,
      "learning_rate": 0.00044341611996251174,
      "loss": 2.4132,
      "step": 2900
    },
    {
      "epoch": 0.3514526710402999,
      "grad_norm": 4.945125579833984,
      "learning_rate": 0.00044146360512339894,
      "loss": 2.4496,
      "step": 3000
    },
    {
      "epoch": 0.3631677600749766,
      "grad_norm": 3.752572536468506,
      "learning_rate": 0.00043951109028428614,
      "loss": 2.3852,
      "step": 3100
    },
    {
      "epoch": 0.37488284910965325,
      "grad_norm": 4.5954365730285645,
      "learning_rate": 0.0004375585754451734,
      "loss": 2.3953,
      "step": 3200
    },
    {
      "epoch": 0.3865979381443299,
      "grad_norm": 4.452876567840576,
      "learning_rate": 0.0004356060606060606,
      "loss": 2.4107,
      "step": 3300
    },
    {
      "epoch": 0.3983130271790066,
      "grad_norm": 3.6116762161254883,
      "learning_rate": 0.00043365354576694785,
      "loss": 2.3995,
      "step": 3400
    },
    {
      "epoch": 0.41002811621368324,
      "grad_norm": 3.523653984069824,
      "learning_rate": 0.0004317010309278351,
      "loss": 2.4031,
      "step": 3500
    },
    {
      "epoch": 0.4217432052483599,
      "grad_norm": 3.8339104652404785,
      "learning_rate": 0.0004297485160887223,
      "loss": 2.3718,
      "step": 3600
    },
    {
      "epoch": 0.43345829428303656,
      "grad_norm": 4.194619178771973,
      "learning_rate": 0.0004277960012496095,
      "loss": 2.3376,
      "step": 3700
    },
    {
      "epoch": 0.4451733833177132,
      "grad_norm": 5.167135715484619,
      "learning_rate": 0.00042584348641049676,
      "loss": 2.3649,
      "step": 3800
    },
    {
      "epoch": 0.4568884723523899,
      "grad_norm": 4.886307716369629,
      "learning_rate": 0.00042389097157138396,
      "loss": 2.3776,
      "step": 3900
    },
    {
      "epoch": 0.46860356138706655,
      "grad_norm": 3.888739585876465,
      "learning_rate": 0.00042193845673227116,
      "loss": 2.3479,
      "step": 4000
    },
    {
      "epoch": 0.4803186504217432,
      "grad_norm": 4.058990001678467,
      "learning_rate": 0.0004199859418931584,
      "loss": 2.3838,
      "step": 4100
    },
    {
      "epoch": 0.49203373945641987,
      "grad_norm": 4.686529636383057,
      "learning_rate": 0.0004180334270540456,
      "loss": 2.3703,
      "step": 4200
    },
    {
      "epoch": 0.5037488284910965,
      "grad_norm": 5.40146017074585,
      "learning_rate": 0.0004160809122149328,
      "loss": 2.3643,
      "step": 4300
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 3.8870444297790527,
      "learning_rate": 0.0004141479225242112,
      "loss": 2.3662,
      "step": 4400
    },
    {
      "epoch": 0.5271790065604499,
      "grad_norm": 5.332303047180176,
      "learning_rate": 0.0004121954076850984,
      "loss": 2.333,
      "step": 4500
    },
    {
      "epoch": 0.5388940955951266,
      "grad_norm": 4.039228439331055,
      "learning_rate": 0.00041024289284598563,
      "loss": 2.3487,
      "step": 4600
    },
    {
      "epoch": 0.5506091846298032,
      "grad_norm": 4.647162914276123,
      "learning_rate": 0.00040829037800687283,
      "loss": 2.3046,
      "step": 4700
    },
    {
      "epoch": 0.5623242736644799,
      "grad_norm": 5.383174896240234,
      "learning_rate": 0.0004063378631677601,
      "loss": 2.3511,
      "step": 4800
    },
    {
      "epoch": 0.5740393626991566,
      "grad_norm": 4.8383965492248535,
      "learning_rate": 0.00040438534832864734,
      "loss": 2.3121,
      "step": 4900
    },
    {
      "epoch": 0.5857544517338332,
      "grad_norm": 5.076219081878662,
      "learning_rate": 0.00040243283348953454,
      "loss": 2.2855,
      "step": 5000
    },
    {
      "epoch": 0.5974695407685099,
      "grad_norm": 3.8753325939178467,
      "learning_rate": 0.00040048031865042174,
      "loss": 2.2595,
      "step": 5100
    },
    {
      "epoch": 0.6091846298031866,
      "grad_norm": 4.643612861633301,
      "learning_rate": 0.000398527803811309,
      "loss": 2.3494,
      "step": 5200
    },
    {
      "epoch": 0.6208997188378632,
      "grad_norm": 4.3273162841796875,
      "learning_rate": 0.0003965752889721962,
      "loss": 2.3307,
      "step": 5300
    },
    {
      "epoch": 0.6326148078725399,
      "grad_norm": 4.2318878173828125,
      "learning_rate": 0.0003946227741330834,
      "loss": 2.2733,
      "step": 5400
    },
    {
      "epoch": 0.6443298969072165,
      "grad_norm": 4.267562389373779,
      "learning_rate": 0.00039267025929397065,
      "loss": 2.3069,
      "step": 5500
    },
    {
      "epoch": 0.6560449859418932,
      "grad_norm": 3.9141182899475098,
      "learning_rate": 0.00039071774445485785,
      "loss": 2.3252,
      "step": 5600
    },
    {
      "epoch": 0.6677600749765699,
      "grad_norm": 3.6876492500305176,
      "learning_rate": 0.00038876522961574505,
      "loss": 2.24,
      "step": 5700
    },
    {
      "epoch": 0.6794751640112465,
      "grad_norm": 4.3677239418029785,
      "learning_rate": 0.0003868127147766323,
      "loss": 2.2614,
      "step": 5800
    },
    {
      "epoch": 0.6911902530459232,
      "grad_norm": 4.389099597930908,
      "learning_rate": 0.00038486019993751956,
      "loss": 2.2979,
      "step": 5900
    },
    {
      "epoch": 0.7029053420805998,
      "grad_norm": 4.585690021514893,
      "learning_rate": 0.00038290768509840676,
      "loss": 2.2969,
      "step": 6000
    },
    {
      "epoch": 0.7146204311152765,
      "grad_norm": 4.842065334320068,
      "learning_rate": 0.000380955170259294,
      "loss": 2.2401,
      "step": 6100
    },
    {
      "epoch": 0.7263355201499532,
      "grad_norm": 4.155399322509766,
      "learning_rate": 0.0003790026554201812,
      "loss": 2.2697,
      "step": 6200
    },
    {
      "epoch": 0.7380506091846298,
      "grad_norm": 4.409428119659424,
      "learning_rate": 0.0003770501405810684,
      "loss": 2.28,
      "step": 6300
    },
    {
      "epoch": 0.7497656982193065,
      "grad_norm": 4.113968372344971,
      "learning_rate": 0.00037509762574195566,
      "loss": 2.2956,
      "step": 6400
    },
    {
      "epoch": 0.7614807872539832,
      "grad_norm": 4.316977024078369,
      "learning_rate": 0.00037316463605123403,
      "loss": 2.3111,
      "step": 6500
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 5.337570667266846,
      "learning_rate": 0.00037121212121212123,
      "loss": 2.2736,
      "step": 6600
    },
    {
      "epoch": 0.7849109653233365,
      "grad_norm": 6.575435638427734,
      "learning_rate": 0.00036925960637300843,
      "loss": 2.3138,
      "step": 6700
    },
    {
      "epoch": 0.7966260543580131,
      "grad_norm": 4.418577194213867,
      "learning_rate": 0.0003673070915338957,
      "loss": 2.3015,
      "step": 6800
    },
    {
      "epoch": 0.8083411433926898,
      "grad_norm": 3.757169723510742,
      "learning_rate": 0.0003653545766947829,
      "loss": 2.2736,
      "step": 6900
    },
    {
      "epoch": 0.8200562324273665,
      "grad_norm": 4.0476460456848145,
      "learning_rate": 0.0003634020618556701,
      "loss": 2.2545,
      "step": 7000
    },
    {
      "epoch": 0.8317713214620431,
      "grad_norm": 5.351390838623047,
      "learning_rate": 0.00036144954701655734,
      "loss": 2.2855,
      "step": 7100
    },
    {
      "epoch": 0.8434864104967198,
      "grad_norm": 3.9562110900878906,
      "learning_rate": 0.00035949703217744454,
      "loss": 2.2595,
      "step": 7200
    },
    {
      "epoch": 0.8552014995313965,
      "grad_norm": 6.00460958480835,
      "learning_rate": 0.0003575445173383318,
      "loss": 2.2827,
      "step": 7300
    },
    {
      "epoch": 0.8669165885660731,
      "grad_norm": 5.190948486328125,
      "learning_rate": 0.00035559200249921905,
      "loss": 2.2614,
      "step": 7400
    },
    {
      "epoch": 0.8786316776007498,
      "grad_norm": 4.565726280212402,
      "learning_rate": 0.00035363948766010625,
      "loss": 2.2787,
      "step": 7500
    },
    {
      "epoch": 0.8903467666354264,
      "grad_norm": 4.300930023193359,
      "learning_rate": 0.00035168697282099345,
      "loss": 2.2745,
      "step": 7600
    },
    {
      "epoch": 0.9020618556701031,
      "grad_norm": 3.838721513748169,
      "learning_rate": 0.0003497344579818807,
      "loss": 2.2734,
      "step": 7700
    },
    {
      "epoch": 0.9137769447047798,
      "grad_norm": 8.013632774353027,
      "learning_rate": 0.0003477819431427679,
      "loss": 2.263,
      "step": 7800
    },
    {
      "epoch": 0.9254920337394564,
      "grad_norm": 3.416085958480835,
      "learning_rate": 0.0003458294283036551,
      "loss": 2.2659,
      "step": 7900
    },
    {
      "epoch": 0.9372071227741331,
      "grad_norm": 5.524442195892334,
      "learning_rate": 0.00034387691346454235,
      "loss": 2.2886,
      "step": 8000
    },
    {
      "epoch": 0.9489222118088098,
      "grad_norm": 4.156816482543945,
      "learning_rate": 0.00034192439862542955,
      "loss": 2.1879,
      "step": 8100
    },
    {
      "epoch": 0.9606373008434864,
      "grad_norm": 4.5861430168151855,
      "learning_rate": 0.00033997188378631676,
      "loss": 2.1845,
      "step": 8200
    },
    {
      "epoch": 0.9723523898781631,
      "grad_norm": 4.352312088012695,
      "learning_rate": 0.000338019368947204,
      "loss": 2.2455,
      "step": 8300
    },
    {
      "epoch": 0.9840674789128397,
      "grad_norm": 4.853271484375,
      "learning_rate": 0.0003360668541080912,
      "loss": 2.2741,
      "step": 8400
    },
    {
      "epoch": 0.9957825679475164,
      "grad_norm": 5.264669418334961,
      "learning_rate": 0.00033411433926897846,
      "loss": 2.2515,
      "step": 8500
    },
    {
      "epoch": 1.0,
      "eval_runtime": 123.7813,
      "eval_samples_per_second": 275.849,
      "eval_steps_per_second": 17.248,
      "step": 8536
    },
    {
      "epoch": 1.007497656982193,
      "grad_norm": 4.894635200500488,
      "learning_rate": 0.0003321618244298657,
      "loss": 2.288,
      "step": 8600
    },
    {
      "epoch": 1.0192127460168696,
      "grad_norm": 4.195326805114746,
      "learning_rate": 0.0003302093095907529,
      "loss": 2.2138,
      "step": 8700
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 5.136669158935547,
      "learning_rate": 0.0003282763199000313,
      "loss": 2.1993,
      "step": 8800
    },
    {
      "epoch": 1.042642924086223,
      "grad_norm": 4.6784563064575195,
      "learning_rate": 0.0003263238050609185,
      "loss": 2.1968,
      "step": 8900
    },
    {
      "epoch": 1.0543580131208996,
      "grad_norm": 4.07340145111084,
      "learning_rate": 0.0003243712902218057,
      "loss": 2.1975,
      "step": 9000
    },
    {
      "epoch": 1.0660731021555763,
      "grad_norm": 5.800548553466797,
      "learning_rate": 0.00032241877538269294,
      "loss": 2.1375,
      "step": 9100
    },
    {
      "epoch": 1.077788191190253,
      "grad_norm": 5.256445407867432,
      "learning_rate": 0.00032046626054358014,
      "loss": 2.2456,
      "step": 9200
    },
    {
      "epoch": 1.0895032802249296,
      "grad_norm": 4.336531162261963,
      "learning_rate": 0.00031851374570446734,
      "loss": 2.2494,
      "step": 9300
    },
    {
      "epoch": 1.1012183692596063,
      "grad_norm": 5.144009113311768,
      "learning_rate": 0.0003165612308653546,
      "loss": 2.2354,
      "step": 9400
    },
    {
      "epoch": 1.1129334582942831,
      "grad_norm": 5.502011299133301,
      "learning_rate": 0.0003146087160262418,
      "loss": 2.2445,
      "step": 9500
    },
    {
      "epoch": 1.1246485473289598,
      "grad_norm": 3.67040753364563,
      "learning_rate": 0.000312656201187129,
      "loss": 2.1565,
      "step": 9600
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 4.654633522033691,
      "learning_rate": 0.00031070368634801625,
      "loss": 2.2506,
      "step": 9700
    },
    {
      "epoch": 1.148078725398313,
      "grad_norm": 4.348445415496826,
      "learning_rate": 0.00030875117150890345,
      "loss": 2.181,
      "step": 9800
    },
    {
      "epoch": 1.1597938144329896,
      "grad_norm": 5.01110315322876,
      "learning_rate": 0.0003067986566697907,
      "loss": 2.2179,
      "step": 9900
    },
    {
      "epoch": 1.1715089034676662,
      "grad_norm": 4.114377498626709,
      "learning_rate": 0.00030484614183067795,
      "loss": 2.1605,
      "step": 10000
    },
    {
      "epoch": 1.1832239925023431,
      "grad_norm": 3.791771173477173,
      "learning_rate": 0.00030289362699156515,
      "loss": 2.2326,
      "step": 10100
    },
    {
      "epoch": 1.1949390815370198,
      "grad_norm": 4.540032863616943,
      "learning_rate": 0.00030094111215245235,
      "loss": 2.1978,
      "step": 10200
    },
    {
      "epoch": 1.2066541705716964,
      "grad_norm": 4.079665660858154,
      "learning_rate": 0.0002989885973133396,
      "loss": 2.2654,
      "step": 10300
    },
    {
      "epoch": 1.218369259606373,
      "grad_norm": 6.181673049926758,
      "learning_rate": 0.0002970360824742268,
      "loss": 2.1892,
      "step": 10400
    },
    {
      "epoch": 1.2300843486410498,
      "grad_norm": 4.535326957702637,
      "learning_rate": 0.000295083567635114,
      "loss": 2.2236,
      "step": 10500
    },
    {
      "epoch": 1.2417994376757264,
      "grad_norm": 4.103367328643799,
      "learning_rate": 0.00029313105279600126,
      "loss": 2.1862,
      "step": 10600
    },
    {
      "epoch": 1.2535145267104029,
      "grad_norm": 4.458976745605469,
      "learning_rate": 0.00029117853795688846,
      "loss": 2.1239,
      "step": 10700
    },
    {
      "epoch": 1.2652296157450795,
      "grad_norm": 4.611008644104004,
      "learning_rate": 0.00028922602311777566,
      "loss": 2.2411,
      "step": 10800
    },
    {
      "epoch": 1.2769447047797562,
      "grad_norm": 4.014966011047363,
      "learning_rate": 0.0002872735082786629,
      "loss": 2.112,
      "step": 10900
    },
    {
      "epoch": 1.2886597938144329,
      "grad_norm": 4.2378082275390625,
      "learning_rate": 0.0002853405185879413,
      "loss": 2.1661,
      "step": 11000
    },
    {
      "epoch": 1.3003748828491095,
      "grad_norm": 5.176579475402832,
      "learning_rate": 0.0002833880037488285,
      "loss": 2.2407,
      "step": 11100
    },
    {
      "epoch": 1.3120899718837864,
      "grad_norm": 4.970809459686279,
      "learning_rate": 0.0002814354889097157,
      "loss": 2.1452,
      "step": 11200
    },
    {
      "epoch": 1.323805060918463,
      "grad_norm": 5.525918960571289,
      "learning_rate": 0.000279482974070603,
      "loss": 2.2201,
      "step": 11300
    },
    {
      "epoch": 1.3355201499531397,
      "grad_norm": 6.615675926208496,
      "learning_rate": 0.0002775304592314902,
      "loss": 2.2278,
      "step": 11400
    },
    {
      "epoch": 1.3472352389878164,
      "grad_norm": 5.623871326446533,
      "learning_rate": 0.0002755779443923774,
      "loss": 2.2614,
      "step": 11500
    },
    {
      "epoch": 1.358950328022493,
      "grad_norm": 5.835113525390625,
      "learning_rate": 0.00027362542955326465,
      "loss": 2.1848,
      "step": 11600
    },
    {
      "epoch": 1.3706654170571697,
      "grad_norm": 3.4397833347320557,
      "learning_rate": 0.00027167291471415185,
      "loss": 2.217,
      "step": 11700
    },
    {
      "epoch": 1.3823805060918464,
      "grad_norm": 4.224558353424072,
      "learning_rate": 0.00026972039987503905,
      "loss": 2.2126,
      "step": 11800
    },
    {
      "epoch": 1.394095595126523,
      "grad_norm": 4.717529773712158,
      "learning_rate": 0.0002677678850359263,
      "loss": 2.1341,
      "step": 11900
    },
    {
      "epoch": 1.4058106841611997,
      "grad_norm": 5.6782355308532715,
      "learning_rate": 0.0002658153701968135,
      "loss": 2.1152,
      "step": 12000
    },
    {
      "epoch": 1.4175257731958764,
      "grad_norm": 4.407451629638672,
      "learning_rate": 0.0002638628553577007,
      "loss": 2.1813,
      "step": 12100
    },
    {
      "epoch": 1.429240862230553,
      "grad_norm": 5.474334239959717,
      "learning_rate": 0.0002619103405185879,
      "loss": 2.1814,
      "step": 12200
    },
    {
      "epoch": 1.4409559512652297,
      "grad_norm": 5.3528289794921875,
      "learning_rate": 0.00025995782567947515,
      "loss": 2.1848,
      "step": 12300
    },
    {
      "epoch": 1.4526710402999063,
      "grad_norm": 5.235598564147949,
      "learning_rate": 0.0002580053108403624,
      "loss": 2.243,
      "step": 12400
    },
    {
      "epoch": 1.464386129334583,
      "grad_norm": 4.841535568237305,
      "learning_rate": 0.0002560527960012496,
      "loss": 2.1884,
      "step": 12500
    },
    {
      "epoch": 1.4761012183692597,
      "grad_norm": 5.45502233505249,
      "learning_rate": 0.00025410028116213686,
      "loss": 2.2303,
      "step": 12600
    },
    {
      "epoch": 1.4878163074039363,
      "grad_norm": 4.919997215270996,
      "learning_rate": 0.00025214776632302406,
      "loss": 2.1265,
      "step": 12700
    },
    {
      "epoch": 1.499531396438613,
      "grad_norm": 4.79765510559082,
      "learning_rate": 0.00025019525148391126,
      "loss": 2.212,
      "step": 12800
    },
    {
      "epoch": 1.5112464854732894,
      "grad_norm": 4.3830108642578125,
      "learning_rate": 0.0002482427366447985,
      "loss": 2.1797,
      "step": 12900
    },
    {
      "epoch": 1.522961574507966,
      "grad_norm": 5.160102844238281,
      "learning_rate": 0.00024630974695407683,
      "loss": 2.1355,
      "step": 13000
    },
    {
      "epoch": 1.5346766635426428,
      "grad_norm": 5.406757831573486,
      "learning_rate": 0.0002443572321149641,
      "loss": 2.1823,
      "step": 13100
    },
    {
      "epoch": 1.5463917525773194,
      "grad_norm": 4.871207237243652,
      "learning_rate": 0.0002424047172758513,
      "loss": 2.1717,
      "step": 13200
    },
    {
      "epoch": 1.558106841611996,
      "grad_norm": 5.115520000457764,
      "learning_rate": 0.0002404522024367385,
      "loss": 2.1735,
      "step": 13300
    },
    {
      "epoch": 1.569821930646673,
      "grad_norm": 6.477055549621582,
      "learning_rate": 0.00023851921274601687,
      "loss": 2.0866,
      "step": 13400
    },
    {
      "epoch": 1.5815370196813496,
      "grad_norm": 4.554823875427246,
      "learning_rate": 0.0002365666979069041,
      "loss": 2.1098,
      "step": 13500
    },
    {
      "epoch": 1.5932521087160263,
      "grad_norm": 3.499234199523926,
      "learning_rate": 0.0002346141830677913,
      "loss": 2.213,
      "step": 13600
    },
    {
      "epoch": 1.604967197750703,
      "grad_norm": 5.895769119262695,
      "learning_rate": 0.00023266166822867855,
      "loss": 2.2277,
      "step": 13700
    },
    {
      "epoch": 1.6166822867853796,
      "grad_norm": 5.769434928894043,
      "learning_rate": 0.00023070915338956578,
      "loss": 2.1408,
      "step": 13800
    },
    {
      "epoch": 1.6283973758200563,
      "grad_norm": 5.023155212402344,
      "learning_rate": 0.00022875663855045298,
      "loss": 2.1413,
      "step": 13900
    },
    {
      "epoch": 1.640112464854733,
      "grad_norm": 4.376203536987305,
      "learning_rate": 0.0002268041237113402,
      "loss": 2.1137,
      "step": 14000
    },
    {
      "epoch": 1.6518275538894096,
      "grad_norm": 4.3528218269348145,
      "learning_rate": 0.00022485160887222744,
      "loss": 2.1549,
      "step": 14100
    },
    {
      "epoch": 1.6635426429240863,
      "grad_norm": 4.264064788818359,
      "learning_rate": 0.00022289909403311464,
      "loss": 2.08,
      "step": 14200
    },
    {
      "epoch": 1.675257731958763,
      "grad_norm": 6.6028618812561035,
      "learning_rate": 0.0002209465791940019,
      "loss": 2.1898,
      "step": 14300
    },
    {
      "epoch": 1.6869728209934396,
      "grad_norm": 3.9227466583251953,
      "learning_rate": 0.00021899406435488912,
      "loss": 2.1687,
      "step": 14400
    },
    {
      "epoch": 1.6986879100281163,
      "grad_norm": 4.888406753540039,
      "learning_rate": 0.00021704154951577632,
      "loss": 2.1638,
      "step": 14500
    },
    {
      "epoch": 1.710402999062793,
      "grad_norm": 4.751535415649414,
      "learning_rate": 0.00021508903467666355,
      "loss": 2.1678,
      "step": 14600
    },
    {
      "epoch": 1.7221180880974696,
      "grad_norm": 4.032752990722656,
      "learning_rate": 0.00021313651983755077,
      "loss": 2.1369,
      "step": 14700
    },
    {
      "epoch": 1.7338331771321462,
      "grad_norm": 5.936219215393066,
      "learning_rate": 0.00021118400499843797,
      "loss": 2.1908,
      "step": 14800
    },
    {
      "epoch": 1.745548266166823,
      "grad_norm": 4.044866561889648,
      "learning_rate": 0.00020923149015932523,
      "loss": 2.105,
      "step": 14900
    },
    {
      "epoch": 1.7572633552014996,
      "grad_norm": 4.907809257507324,
      "learning_rate": 0.00020727897532021245,
      "loss": 2.1866,
      "step": 15000
    },
    {
      "epoch": 1.7689784442361762,
      "grad_norm": 5.879981517791748,
      "learning_rate": 0.00020532646048109965,
      "loss": 2.1553,
      "step": 15100
    },
    {
      "epoch": 1.780693533270853,
      "grad_norm": 5.880300045013428,
      "learning_rate": 0.00020337394564198688,
      "loss": 2.191,
      "step": 15200
    },
    {
      "epoch": 1.7924086223055296,
      "grad_norm": 5.595547676086426,
      "learning_rate": 0.0002014214308028741,
      "loss": 2.1518,
      "step": 15300
    },
    {
      "epoch": 1.8041237113402062,
      "grad_norm": 6.466241836547852,
      "learning_rate": 0.0001994689159637613,
      "loss": 2.1534,
      "step": 15400
    },
    {
      "epoch": 1.8158388003748829,
      "grad_norm": 4.299615859985352,
      "learning_rate": 0.00019751640112464856,
      "loss": 2.1752,
      "step": 15500
    },
    {
      "epoch": 1.8275538894095595,
      "grad_norm": 4.99028205871582,
      "learning_rate": 0.0001955638862855358,
      "loss": 2.1306,
      "step": 15600
    },
    {
      "epoch": 1.8392689784442362,
      "grad_norm": 6.638576984405518,
      "learning_rate": 0.000193611371446423,
      "loss": 2.1707,
      "step": 15700
    },
    {
      "epoch": 1.8509840674789129,
      "grad_norm": 5.687094211578369,
      "learning_rate": 0.00019165885660731022,
      "loss": 2.2003,
      "step": 15800
    },
    {
      "epoch": 1.8626991565135895,
      "grad_norm": 4.3068623542785645,
      "learning_rate": 0.00018970634176819745,
      "loss": 2.1445,
      "step": 15900
    },
    {
      "epoch": 1.8744142455482662,
      "grad_norm": 3.897714853286743,
      "learning_rate": 0.00018775382692908467,
      "loss": 2.1817,
      "step": 16000
    },
    {
      "epoch": 1.8861293345829429,
      "grad_norm": 4.328420162200928,
      "learning_rate": 0.0001858013120899719,
      "loss": 2.148,
      "step": 16100
    },
    {
      "epoch": 1.8978444236176195,
      "grad_norm": 4.292954921722412,
      "learning_rate": 0.00018384879725085913,
      "loss": 2.2018,
      "step": 16200
    },
    {
      "epoch": 1.9095595126522962,
      "grad_norm": 4.428797721862793,
      "learning_rate": 0.00018189628241174633,
      "loss": 2.1506,
      "step": 16300
    },
    {
      "epoch": 1.9212746016869728,
      "grad_norm": 4.4526047706604,
      "learning_rate": 0.00017994376757263355,
      "loss": 2.0623,
      "step": 16400
    },
    {
      "epoch": 1.9329896907216495,
      "grad_norm": 4.395059108734131,
      "learning_rate": 0.00017799125273352078,
      "loss": 2.1881,
      "step": 16500
    },
    {
      "epoch": 1.9447047797563262,
      "grad_norm": 5.536884784698486,
      "learning_rate": 0.000176038737894408,
      "loss": 2.1049,
      "step": 16600
    },
    {
      "epoch": 1.9564198687910028,
      "grad_norm": 4.644294738769531,
      "learning_rate": 0.00017408622305529524,
      "loss": 2.1458,
      "step": 16700
    },
    {
      "epoch": 1.9681349578256795,
      "grad_norm": 5.255547046661377,
      "learning_rate": 0.00017213370821618244,
      "loss": 2.0761,
      "step": 16800
    },
    {
      "epoch": 1.9798500468603561,
      "grad_norm": 5.8051042556762695,
      "learning_rate": 0.00017018119337706966,
      "loss": 2.1358,
      "step": 16900
    },
    {
      "epoch": 1.9915651358950328,
      "grad_norm": 5.674991130828857,
      "learning_rate": 0.0001682286785379569,
      "loss": 2.1186,
      "step": 17000
    },
    {
      "epoch": 2.0,
      "eval_runtime": 180.1342,
      "eval_samples_per_second": 189.553,
      "eval_steps_per_second": 11.852,
      "step": 17072
    },
    {
      "epoch": 2.0032802249297093,
      "grad_norm": 5.065182209014893,
      "learning_rate": 0.0001662761636988441,
      "loss": 2.1937,
      "step": 17100
    },
    {
      "epoch": 2.014995313964386,
      "grad_norm": 5.546896457672119,
      "learning_rate": 0.00016432364885973134,
      "loss": 2.1949,
      "step": 17200
    },
    {
      "epoch": 2.0267104029990626,
      "grad_norm": 5.698789596557617,
      "learning_rate": 0.00016237113402061857,
      "loss": 2.1714,
      "step": 17300
    },
    {
      "epoch": 2.0384254920337392,
      "grad_norm": 4.937030792236328,
      "learning_rate": 0.00016041861918150577,
      "loss": 2.1427,
      "step": 17400
    },
    {
      "epoch": 2.050140581068416,
      "grad_norm": 4.280257701873779,
      "learning_rate": 0.00015848562949078414,
      "loss": 2.1081,
      "step": 17500
    },
    {
      "epoch": 2.0618556701030926,
      "grad_norm": 5.955200672149658,
      "learning_rate": 0.00015653311465167136,
      "loss": 2.1897,
      "step": 17600
    },
    {
      "epoch": 2.0735707591377697,
      "grad_norm": 5.385845184326172,
      "learning_rate": 0.0001545805998125586,
      "loss": 2.1357,
      "step": 17700
    },
    {
      "epoch": 2.085285848172446,
      "grad_norm": 5.715409278869629,
      "learning_rate": 0.0001526280849734458,
      "loss": 2.151,
      "step": 17800
    },
    {
      "epoch": 2.097000937207123,
      "grad_norm": 3.6161279678344727,
      "learning_rate": 0.00015067557013433302,
      "loss": 2.1098,
      "step": 17900
    },
    {
      "epoch": 2.108716026241799,
      "grad_norm": 5.530666351318359,
      "learning_rate": 0.00014872305529522024,
      "loss": 2.1779,
      "step": 18000
    },
    {
      "epoch": 2.1204311152764763,
      "grad_norm": 4.326141357421875,
      "learning_rate": 0.00014677054045610747,
      "loss": 2.0884,
      "step": 18100
    },
    {
      "epoch": 2.1321462043111525,
      "grad_norm": 4.651233673095703,
      "learning_rate": 0.0001448180256169947,
      "loss": 2.1635,
      "step": 18200
    },
    {
      "epoch": 2.1438612933458296,
      "grad_norm": 5.112088203430176,
      "learning_rate": 0.0001428655107778819,
      "loss": 2.0819,
      "step": 18300
    },
    {
      "epoch": 2.155576382380506,
      "grad_norm": 6.527758598327637,
      "learning_rate": 0.00014091299593876913,
      "loss": 2.1429,
      "step": 18400
    },
    {
      "epoch": 2.167291471415183,
      "grad_norm": 5.463602542877197,
      "learning_rate": 0.00013896048109965635,
      "loss": 2.1096,
      "step": 18500
    },
    {
      "epoch": 2.179006560449859,
      "grad_norm": 6.233996391296387,
      "learning_rate": 0.00013700796626054358,
      "loss": 2.0663,
      "step": 18600
    },
    {
      "epoch": 2.1907216494845363,
      "grad_norm": 4.179226875305176,
      "learning_rate": 0.0001350554514214308,
      "loss": 2.0303,
      "step": 18700
    },
    {
      "epoch": 2.2024367385192125,
      "grad_norm": 5.780211448669434,
      "learning_rate": 0.00013310293658231804,
      "loss": 2.1187,
      "step": 18800
    },
    {
      "epoch": 2.2141518275538896,
      "grad_norm": 4.954870700836182,
      "learning_rate": 0.00013115042174320524,
      "loss": 2.0208,
      "step": 18900
    },
    {
      "epoch": 2.2258669165885663,
      "grad_norm": 4.055974006652832,
      "learning_rate": 0.00012919790690409246,
      "loss": 2.0895,
      "step": 19000
    },
    {
      "epoch": 2.237582005623243,
      "grad_norm": 4.303653240203857,
      "learning_rate": 0.00012724539206497972,
      "loss": 2.1019,
      "step": 19100
    },
    {
      "epoch": 2.2492970946579196,
      "grad_norm": 4.501425743103027,
      "learning_rate": 0.00012529287722586692,
      "loss": 2.1266,
      "step": 19200
    },
    {
      "epoch": 2.2610121836925963,
      "grad_norm": 3.8757152557373047,
      "learning_rate": 0.00012334036238675414,
      "loss": 2.1114,
      "step": 19300
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 4.380710124969482,
      "learning_rate": 0.00012138784754764136,
      "loss": 2.1194,
      "step": 19400
    },
    {
      "epoch": 2.2844423617619496,
      "grad_norm": 5.0784077644348145,
      "learning_rate": 0.00011945485785691972,
      "loss": 2.0829,
      "step": 19500
    },
    {
      "epoch": 2.296157450796626,
      "grad_norm": 5.592013359069824,
      "learning_rate": 0.00011750234301780694,
      "loss": 2.1167,
      "step": 19600
    },
    {
      "epoch": 2.307872539831303,
      "grad_norm": 4.706258296966553,
      "learning_rate": 0.00011554982817869416,
      "loss": 2.0927,
      "step": 19700
    },
    {
      "epoch": 2.319587628865979,
      "grad_norm": 5.250688076019287,
      "learning_rate": 0.00011359731333958139,
      "loss": 2.1332,
      "step": 19800
    },
    {
      "epoch": 2.3313027179006562,
      "grad_norm": 4.643255233764648,
      "learning_rate": 0.0001116447985004686,
      "loss": 2.1114,
      "step": 19900
    },
    {
      "epoch": 2.3430178069353325,
      "grad_norm": 4.764854431152344,
      "learning_rate": 0.00010969228366135583,
      "loss": 2.113,
      "step": 20000
    },
    {
      "epoch": 2.3547328959700096,
      "grad_norm": 4.744647979736328,
      "learning_rate": 0.00010773976882224306,
      "loss": 2.1019,
      "step": 20100
    },
    {
      "epoch": 2.3664479850046862,
      "grad_norm": 5.657220840454102,
      "learning_rate": 0.00010578725398313027,
      "loss": 2.0882,
      "step": 20200
    },
    {
      "epoch": 2.378163074039363,
      "grad_norm": 6.271576404571533,
      "learning_rate": 0.00010383473914401749,
      "loss": 2.0813,
      "step": 20300
    },
    {
      "epoch": 2.3898781630740396,
      "grad_norm": 3.488858938217163,
      "learning_rate": 0.00010188222430490473,
      "loss": 2.2289,
      "step": 20400
    },
    {
      "epoch": 2.401593252108716,
      "grad_norm": 4.688858509063721,
      "learning_rate": 9.992970946579194e-05,
      "loss": 2.058,
      "step": 20500
    },
    {
      "epoch": 2.413308341143393,
      "grad_norm": 4.660844802856445,
      "learning_rate": 9.797719462667915e-05,
      "loss": 2.0903,
      "step": 20600
    },
    {
      "epoch": 2.4250234301780695,
      "grad_norm": 5.021270751953125,
      "learning_rate": 9.60246797875664e-05,
      "loss": 2.098,
      "step": 20700
    },
    {
      "epoch": 2.436738519212746,
      "grad_norm": 5.289228439331055,
      "learning_rate": 9.407216494845361e-05,
      "loss": 2.1703,
      "step": 20800
    },
    {
      "epoch": 2.448453608247423,
      "grad_norm": 5.539126396179199,
      "learning_rate": 9.211965010934082e-05,
      "loss": 2.12,
      "step": 20900
    },
    {
      "epoch": 2.4601686972820995,
      "grad_norm": 4.833462238311768,
      "learning_rate": 9.016713527022806e-05,
      "loss": 2.1417,
      "step": 21000
    },
    {
      "epoch": 2.471883786316776,
      "grad_norm": 6.231518745422363,
      "learning_rate": 8.821462043111528e-05,
      "loss": 2.1935,
      "step": 21100
    },
    {
      "epoch": 2.483598875351453,
      "grad_norm": 4.474226474761963,
      "learning_rate": 8.626210559200249e-05,
      "loss": 2.0299,
      "step": 21200
    },
    {
      "epoch": 2.4953139643861295,
      "grad_norm": 6.533238410949707,
      "learning_rate": 8.430959075288973e-05,
      "loss": 2.0909,
      "step": 21300
    },
    {
      "epoch": 2.5070290534208057,
      "grad_norm": 5.420933723449707,
      "learning_rate": 8.235707591377694e-05,
      "loss": 2.1196,
      "step": 21400
    },
    {
      "epoch": 2.518744142455483,
      "grad_norm": 4.119068622589111,
      "learning_rate": 8.040456107466417e-05,
      "loss": 2.1337,
      "step": 21500
    },
    {
      "epoch": 2.530459231490159,
      "grad_norm": 5.397777080535889,
      "learning_rate": 7.847157138394252e-05,
      "loss": 2.0623,
      "step": 21600
    },
    {
      "epoch": 2.542174320524836,
      "grad_norm": 5.140133380889893,
      "learning_rate": 7.651905654482974e-05,
      "loss": 2.0682,
      "step": 21700
    },
    {
      "epoch": 2.5538894095595124,
      "grad_norm": 6.709191799163818,
      "learning_rate": 7.456654170571696e-05,
      "loss": 2.1925,
      "step": 21800
    },
    {
      "epoch": 2.5656044985941895,
      "grad_norm": 4.66639518737793,
      "learning_rate": 7.261402686660419e-05,
      "loss": 2.095,
      "step": 21900
    },
    {
      "epoch": 2.5773195876288657,
      "grad_norm": 4.260064601898193,
      "learning_rate": 7.06615120274914e-05,
      "loss": 2.1437,
      "step": 22000
    },
    {
      "epoch": 2.589034676663543,
      "grad_norm": 4.606982231140137,
      "learning_rate": 6.870899718837863e-05,
      "loss": 2.142,
      "step": 22100
    },
    {
      "epoch": 2.600749765698219,
      "grad_norm": 6.4257941246032715,
      "learning_rate": 6.675648234926586e-05,
      "loss": 2.1791,
      "step": 22200
    },
    {
      "epoch": 2.612464854732896,
      "grad_norm": 5.455758094787598,
      "learning_rate": 6.480396751015307e-05,
      "loss": 2.1477,
      "step": 22300
    },
    {
      "epoch": 2.624179943767573,
      "grad_norm": 4.75686502456665,
      "learning_rate": 6.28514526710403e-05,
      "loss": 2.1308,
      "step": 22400
    },
    {
      "epoch": 2.6358950328022495,
      "grad_norm": 5.0577473640441895,
      "learning_rate": 6.089893783192752e-05,
      "loss": 2.0907,
      "step": 22500
    },
    {
      "epoch": 2.647610121836926,
      "grad_norm": 5.816526889801025,
      "learning_rate": 5.8946422992814746e-05,
      "loss": 2.1488,
      "step": 22600
    },
    {
      "epoch": 2.659325210871603,
      "grad_norm": 6.525591850280762,
      "learning_rate": 5.6993908153701974e-05,
      "loss": 2.1468,
      "step": 22700
    },
    {
      "epoch": 2.6710402999062794,
      "grad_norm": 5.913523197174072,
      "learning_rate": 5.504139331458919e-05,
      "loss": 2.0626,
      "step": 22800
    },
    {
      "epoch": 2.682755388940956,
      "grad_norm": 4.109978199005127,
      "learning_rate": 5.3088878475476415e-05,
      "loss": 2.0706,
      "step": 22900
    },
    {
      "epoch": 2.6944704779756328,
      "grad_norm": 4.36393928527832,
      "learning_rate": 5.113636363636364e-05,
      "loss": 2.1374,
      "step": 23000
    },
    {
      "epoch": 2.7061855670103094,
      "grad_norm": 5.51154088973999,
      "learning_rate": 4.918384879725086e-05,
      "loss": 2.1141,
      "step": 23100
    },
    {
      "epoch": 2.717900656044986,
      "grad_norm": 5.307064056396484,
      "learning_rate": 4.723133395813808e-05,
      "loss": 2.0901,
      "step": 23200
    },
    {
      "epoch": 2.7296157450796628,
      "grad_norm": 6.016906261444092,
      "learning_rate": 4.52788191190253e-05,
      "loss": 2.0653,
      "step": 23300
    },
    {
      "epoch": 2.7413308341143394,
      "grad_norm": 4.460589408874512,
      "learning_rate": 4.332630427991253e-05,
      "loss": 2.1254,
      "step": 23400
    },
    {
      "epoch": 2.753045923149016,
      "grad_norm": 5.075941562652588,
      "learning_rate": 4.137378944079975e-05,
      "loss": 2.096,
      "step": 23500
    },
    {
      "epoch": 2.7647610121836927,
      "grad_norm": 5.366241931915283,
      "learning_rate": 3.942127460168697e-05,
      "loss": 2.0874,
      "step": 23600
    },
    {
      "epoch": 2.7764761012183694,
      "grad_norm": 3.834813356399536,
      "learning_rate": 3.748828491096532e-05,
      "loss": 2.1094,
      "step": 23700
    },
    {
      "epoch": 2.788191190253046,
      "grad_norm": 5.32538366317749,
      "learning_rate": 3.553577007185255e-05,
      "loss": 2.0597,
      "step": 23800
    },
    {
      "epoch": 2.7999062792877227,
      "grad_norm": 4.812305927276611,
      "learning_rate": 3.358325523273977e-05,
      "loss": 2.0213,
      "step": 23900
    },
    {
      "epoch": 2.8116213683223994,
      "grad_norm": 5.2542266845703125,
      "learning_rate": 3.163074039362699e-05,
      "loss": 2.1097,
      "step": 24000
    },
    {
      "epoch": 2.823336457357076,
      "grad_norm": 5.15362024307251,
      "learning_rate": 2.9678225554514217e-05,
      "loss": 2.1072,
      "step": 24100
    },
    {
      "epoch": 2.8350515463917527,
      "grad_norm": 4.822260856628418,
      "learning_rate": 2.7725710715401437e-05,
      "loss": 2.032,
      "step": 24200
    },
    {
      "epoch": 2.8467666354264294,
      "grad_norm": 4.33353853225708,
      "learning_rate": 2.5773195876288658e-05,
      "loss": 2.1661,
      "step": 24300
    },
    {
      "epoch": 2.858481724461106,
      "grad_norm": 4.216516017913818,
      "learning_rate": 2.3820681037175885e-05,
      "loss": 2.0969,
      "step": 24400
    },
    {
      "epoch": 2.8701968134957827,
      "grad_norm": 5.185056209564209,
      "learning_rate": 2.1868166198063105e-05,
      "loss": 2.0922,
      "step": 24500
    },
    {
      "epoch": 2.8819119025304594,
      "grad_norm": 5.646785736083984,
      "learning_rate": 1.991565135895033e-05,
      "loss": 2.0879,
      "step": 24600
    },
    {
      "epoch": 2.893626991565136,
      "grad_norm": 4.684732913970947,
      "learning_rate": 1.796313651983755e-05,
      "loss": 2.0785,
      "step": 24700
    },
    {
      "epoch": 2.9053420805998127,
      "grad_norm": 6.164306163787842,
      "learning_rate": 1.6010621680724773e-05,
      "loss": 2.1062,
      "step": 24800
    },
    {
      "epoch": 2.9170571696344894,
      "grad_norm": 5.611782073974609,
      "learning_rate": 1.4058106841611997e-05,
      "loss": 2.1038,
      "step": 24900
    },
    {
      "epoch": 2.928772258669166,
      "grad_norm": 5.8781867027282715,
      "learning_rate": 1.210559200249922e-05,
      "loss": 2.1007,
      "step": 25000
    },
    {
      "epoch": 2.9404873477038427,
      "grad_norm": 5.955507755279541,
      "learning_rate": 1.0153077163386442e-05,
      "loss": 2.0692,
      "step": 25100
    },
    {
      "epoch": 2.9522024367385193,
      "grad_norm": 4.0433197021484375,
      "learning_rate": 8.200562324273665e-06,
      "loss": 2.0915,
      "step": 25200
    },
    {
      "epoch": 2.963917525773196,
      "grad_norm": 5.225831031799316,
      "learning_rate": 6.2480474851608875e-06,
      "loss": 2.1242,
      "step": 25300
    },
    {
      "epoch": 2.9756326148078727,
      "grad_norm": 5.1370697021484375,
      "learning_rate": 4.2955326460481105e-06,
      "loss": 1.9963,
      "step": 25400
    },
    {
      "epoch": 2.9873477038425493,
      "grad_norm": 6.708714485168457,
      "learning_rate": 2.3430178069353326e-06,
      "loss": 2.122,
      "step": 25500
    }
  ],
  "logging_steps": 100,
  "max_steps": 25608,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6991690614784e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
